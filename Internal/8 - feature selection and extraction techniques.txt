Here's the **complete Python code** for **Week 8** to implement **feature selection and extraction using PCA (Principal Component Analysis)** and **LDA (Linear Discriminant Analysis)** on any dataset like Iris.

‚úÖ This code includes:

* Loading data from a CSV
* Performing PCA and LDA
* Visualizing the results (2D plot)
* Works for **numeric features** and **categorical target**

---

### ‚úÖ üì¶ Required Libraries

```bash
pip install pandas numpy matplotlib scikit-learn
```

---

### ‚úÖ WEEK 8: Full Python Code (PCA & LDA)

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# Step 1: Load CSV data
filename = "iris.csv"  # Change this as needed
data = pd.read_csv(filename)
print("First 5 rows:\n", data.head())

# Step 2: Separate features and target
X = data.iloc[:, :-1]  # all columns except last
y = data.iloc[:, -1]   # last column as target

# Encode target if it's categorical (like 'Iris-setosa')
if y.dtype == 'object':
    le = LabelEncoder()
    y = le.fit_transform(y)

# Step 3: Split into training/testing sets (optional but good practice)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# --- PCA (Unsupervised Dimensionality Reduction) ---
pca = PCA(n_components=2)  # Reduce to 2D
X_pca = pca.fit_transform(X_train)

print("\n--- PCA ---")
print("Explained Variance Ratio:", pca.explained_variance_ratio_)

# Plot PCA result
plt.figure(figsize=(6, 5))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, cmap='viridis', edgecolor='k')
plt.title('PCA Result (2 Components)')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.colorbar()
plt.show()

# --- LDA (Supervised Dimensionality Reduction) ---
lda = LDA(n_components=2)
X_lda = lda.fit_transform(X_train, y_train)

print("\n--- LDA ---")
print("Explained Variance Ratio:", lda.explained_variance_ratio_)

# Plot LDA result
plt.figure(figsize=(6, 5))
plt.scatter(X_lda[:, 0], X_lda[:, 1], c=y_train, cmap='rainbow', edgecolor='k')
plt.title('LDA Result (2 Components)')
plt.xlabel('LD1')
plt.ylabel('LD2')
plt.colorbar()
plt.show()
```

---

### ‚úÖ Sample `iris.csv` File Format (for your test)

```
sepal_length,sepal_width,petal_length,petal_width,class
5.1,3.5,1.4,0.2,Iris-setosa
4.9,3.0,1.4,0.2,Iris-setosa
...
```

---

### üß† Summary

| Method | Type         | Uses Target? | Goal                        |
| ------ | ------------ | ------------ | --------------------------- |
| PCA    | Unsupervised | ‚ùå            | Maximize variance           |
| LDA    | Supervised   | ‚úÖ            | Maximize class separability |

---

Would you like a downloadable example dataset (`iris.csv`) to test this immediately?
